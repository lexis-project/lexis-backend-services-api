// Code generated by go-swagger; DO NOT EDIT.

package data_set_management

// This file was generated by the swagger tool.
// Editing this file might prove futile when you re-run the swagger generate command

import (
	"context"
	"io"

	"github.com/go-openapi/runtime"

	strfmt "github.com/go-openapi/strfmt"
)

//go:generate mockery -name API -inpkg

// API is the interface of the data set management client
type API interface {
	/*
	   AddGridmapEntry adds a d n entry to the d d i b2 s t a g e grid f t p service

	   Add a DN entry to the DDI B2STAGE GridFTP service*/
	AddGridmapEntry(ctx context.Context, params *AddGridmapEntryParams) (*AddGridmapEntryCreated, error)
	/*
	   Certificate downloads public key for w p3 a p is

	   download public key for WP3 APIs*/
	Certificate(ctx context.Context, params *CertificateParams, writer io.Writer) (*CertificateOK, error)
	/*
	   CheckCompressionEncryptionStatus checks the status of compression with encryption

	   Check the status of compression with encryption*/
	CheckCompressionEncryptionStatus(ctx context.Context, params *CheckCompressionEncryptionStatusParams) (*CheckCompressionEncryptionStatusOK, error)
	/*
	   CheckCompressionStatus checks the status of a compression

	   Check the status of a compression*/
	CheckCompressionStatus(ctx context.Context, params *CheckCompressionStatusParams) (*CheckCompressionStatusOK, error)
	/*
	   CheckDecompressionStatus checks the status of a decompression

	   Check the status of a decompression*/
	CheckDecompressionStatus(ctx context.Context, params *CheckDecompressionStatusParams) (*CheckDecompressionStatusOK, error)
	/*
	   CheckDecryptionDecompressionStatus checks the status of decryption with decompression

	   Check the status of decryption with decompression*/
	CheckDecryptionDecompressionStatus(ctx context.Context, params *CheckDecryptionDecompressionStatusParams) (*CheckDecryptionDecompressionStatusOK, error)
	/*
	   CheckDecryptionStatus checks the status of a decryption

	   Check the status of a decryption*/
	CheckDecryptionStatus(ctx context.Context, params *CheckDecryptionStatusParams) (*CheckDecryptionStatusOK, error)
	/*
	   CheckEncryptionStatus checks the status of a encryption

	   Check the status of a encryption*/
	CheckEncryptionStatus(ctx context.Context, params *CheckEncryptionStatusParams) (*CheckEncryptionStatusOK, error)
	/*
	   CheckPIDStatus this is called when a user requests to check the status of the p ID assignment

	   This is called when a user requests to check the status of his data replication*/
	CheckPIDStatus(ctx context.Context, params *CheckPIDStatusParams) (*CheckPIDStatusOK, error)
	/*
	   CheckPermission checks if a user has permission to access a d d i location for writing

	   Check if a user has permission to access a DDI location for writing*/
	CheckPermission(ctx context.Context, params *CheckPermissionParams) (*CheckPermissionOK, error)
	/*
	   CheckReplicateStatus this is called when a user requests to check the status of his data replication

	   This is called when a user requests to check the status of his data replication*/
	CheckReplicateStatus(ctx context.Context, params *CheckReplicateStatusParams) (*CheckReplicateStatusOK, error)
	/*
	   CheckSizeStatus this is called when a user requests to check the status of datasize request

	   This is called when a user requests to check the status of datasize request*/
	CheckSizeStatus(ctx context.Context, params *CheckSizeStatusParams) (*CheckSizeStatusOK, error)
	/*
	   Compress compresses a dataset or subdataset by enqueuing the request for latter processing

	   Compress a dataset or subdataset (by enqueuing the request for latter processing)
	   If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
	    - For public datasets: "public/proj"+hash+"/"+internalID
	    - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
	    - For project datasets: "project/proj"+hash+"/"+internalID
	*/
	Compress(ctx context.Context, params *CompressParams) (*CompressCreated, error)
	/*
	   CompressEncrypt compresses and encrypt a dataset or subdataset by enqueuing the request for latter processing

	   Compress and encrypt a dataset or subdataset (by enqueuing the request for latter processing)
	   If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
	    - For public datasets: "public/proj"+hash+"/"+internalID
	    - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
	    - For project datasets: "project/proj"+hash+"/"+internalID
	*/
	CompressEncrypt(ctx context.Context, params *CompressEncryptParams) (*CompressEncryptCreated, error)
	/*
	   CreateSSHFSExport exports a directory of the d d i for use via SSH f s

	   Export a directory of the DDI for use via SSHFS*/
	CreateSSHFSExport(ctx context.Context, params *CreateSSHFSExportParams) (*CreateSSHFSExportCreated, error)
	/*
	   Decompress decompresses a dataset or subdataset by enqueuing the request for latter processing

	   Decompress a dataset or subdataset (by enqueuing the request for latter processing)
	   If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
	    - For public datasets: "public/proj"+hash+"/"+internalID
	    - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
	    - For project datasets: "project/proj"+hash+"/"+internalID
	*/
	Decompress(ctx context.Context, params *DecompressParams) (*DecompressCreated, error)
	/*
	   Decrypt decrypts a dataset or subdataset by enqueuing the request for latter processing

	   Decrypt a dataset or subdataset (by enqueuing the request for latter processing)
	   If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
	    - For public datasets: "public/proj"+hash+"/"+internalID
	    - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
	    - For project datasets: "project/proj"+hash+"/"+internalID
	*/
	Decrypt(ctx context.Context, params *DecryptParams) (*DecryptCreated, error)
	/*
	   DecryptDecompress decrypts and decompress a dataset or subdataset by enqueuing the request for latter processing

	   Decrypt and decompress a dataset or subdataset (by enqueuing the request for latter processing)
	   If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
	    - For public datasets: "public/proj"+hash+"/"+internalID
	    - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
	    - For project datasets: "project/proj"+hash+"/"+internalID
	*/
	DecryptDecompress(ctx context.Context, params *DecryptDecompressParams) (*DecryptDecompressCreated, error)
	/*
	   DeleteDataset deletes dataset

	   Deletes a dataset by internalID (or subdataset by path)*/
	DeleteDataset(ctx context.Context, params *DeleteDatasetParams) (*DeleteDatasetCreated, *DeleteDatasetNoContent, error)
	/*
	   DeleteDatasetByMetadata searches for datasets based on metadata and delete them

	   Search for datasets based on metadata, and delete them*/
	DeleteDatasetByMetadata(ctx context.Context, params *DeleteDatasetByMetadataParams) (*DeleteDatasetByMetadataNoContent, error)
	/*
	   DeleteSSHFSExport exports a directory of the d d i for use via SSH f s

	   Remove an SSHFS export of a directory of the DDI*/
	DeleteSSHFSExport(ctx context.Context, params *DeleteSSHFSExportParams) (*DeleteSSHFSExportNoContent, error)
	/*
	   DownloadDataset downloads dataset

	   Downloads a dataset. Use the header "Accept: application/octet-stream"
	   or "Accept: [*]/*" to enable the api to provide either zip content (normal
	   operation) or json (error reporting).
	*/
	DownloadDataset(ctx context.Context, params *DownloadDatasetParams, writer io.Writer) (*DownloadDatasetOK, error)
	/*
	   Encrypt encrypts a dataset or subdataset by enqueuing the request for latter processing

	   Encrypt a dataset or subdataset (by enqueuing the request for latter processing)
	   If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
	    - For public datasets: "public/proj"+hash+"/"+internalID
	    - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
	    - For project datasets: "project/proj"+hash+"/"+internalID
	*/
	Encrypt(ctx context.Context, params *EncryptParams) (*EncryptCreated, error)
	/*
	   FilePatch useds to resume the upload

	   The Server SHOULD accept PATCH requests against any upload URL and apply the bytes contained in the message at the given offset specified by the Upload-Offset header. All PATCH requests MUST use Content-Type: application/offset+octet-stream, otherwise the server SHOULD return a 415 Unsupported Media Type status.*/
	FilePatch(ctx context.Context, params *FilePatchParams) (*FilePatchNoContent, error)
	/*
	   FilesDelete addeds by the termination extension

	   When receiving a DELETE request for an existing upload the Server SHOULD free associated resources and MUST respond with the 204 No Content status confirming that the upload was terminated. For all future requests to this URL, the Server SHOULD respond with the 404 Not Found or 410 Gone status.*/
	FilesDelete(ctx context.Context, params *FilesDeleteParams) (*FilesDeleteNoContent, error)
	/*
	   FilesHead useds to determine the offset at which the upload should be continued

	   Used to determine the offset at which the upload should be continued.*/
	FilesHead(ctx context.Context, params *FilesHeadParams) (*FilesHeadOK, error)
	/*
	   Listing lists file contents of a dataset

	   List file contents of a dataset.*/
	Listing(ctx context.Context, params *ListingParams) (*ListingOK, error)
	/*
	   OptionsDatasetUpload requests to gather information about the server s current configuration

	   An OPTIONS request MAY be used to gather information about the Server's current configuration. A successful response indicated by the 204 No Content or 200 OK status MUST contain the Tus-Version header. It MAY include the Tus-Extension and Tus-Max-Size headers.*/
	OptionsDatasetUpload(ctx context.Context, params *OptionsDatasetUploadParams) (*OptionsDatasetUploadOK, *OptionsDatasetUploadNoContent, error)
	/*
	   PID this is called when a user requests p ID assignment to a dataset

	   This is called when a user requests PID assignment to a dataset.*/
	PID(ctx context.Context, params *PIDParams) (*PIDCreated, error)
	/*
	   PostDatasetStagingDownload downloads from staging zone

	   Download from staging zone
	   If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
	    - For public datasets: "public/proj"+hash+"/"+internalID
	    - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
	    - For project datasets: "project/proj"+hash+"/"+internalID
	*/
	PostDatasetStagingDownload(ctx context.Context, params *PostDatasetStagingDownloadParams, writer io.Writer) (*PostDatasetStagingDownloadOK, error)
	/*
	   PostDatasetUpload ans empty p o s t request is used to create a new upload resource the upload length header indicates the size of the entire upload in bytes

	   Endpoint for the Creation extension*/
	PostDatasetUpload(ctx context.Context, params *PostDatasetUploadParams) (*PostDatasetUploadCreated, error)
	/*
	   QueryDatasets searches for datasets based on metadata

	   Search for datasets based on metadata*/
	QueryDatasets(ctx context.Context, params *QueryDatasetsParams) (*QueryDatasetsOK, error)
	/*
	   RemoveGridmapEntry removes a d n entry to the d d i b2 s t a g e grid f t p service

	   Remove a DN entry to the DDI B2STAGE GridFTP service*/
	RemoveGridmapEntry(ctx context.Context, params *RemoveGridmapEntryParams) (*RemoveGridmapEntryNoContent, error)
	/*
	   Replicate this is called when a user requests data to be replicated between different systems the request will be added to the jobs queue

	   This is called when a user requests data to be replicated between different systems. The request will be added to the jobs queue.*/
	Replicate(ctx context.Context, params *ReplicateParams) (*ReplicateCreated, error)
	/*
	   Size this is called when a user requests size of a dataset

	   This is called when a user requests size of a dataset.
	   If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
	    - For public datasets: "public/proj"+hash+"/"+internalID
	    - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
	    - For project datasets: "project/proj"+hash+"/"+internalID
	*/
	Size(ctx context.Context, params *SizeParams) (*SizeCreated, error)
	/*
	   CreateDataset creates a dataset

	   Creates a new dataset*/
	CreateDataset(ctx context.Context, params *CreateDatasetParams) (*CreateDatasetOK, *CreateDatasetCreated, error)
}

// New creates a new data set management API client.
func New(transport runtime.ClientTransport, formats strfmt.Registry, authInfo runtime.ClientAuthInfoWriter) *Client {
	return &Client{
		transport: transport,
		formats:   formats,
		authInfo:  authInfo,
	}
}

/*
Client for data set management API
*/
type Client struct {
	transport runtime.ClientTransport
	formats   strfmt.Registry
	authInfo  runtime.ClientAuthInfoWriter
}

/*
AddGridmapEntry adds a d n entry to the d d i b2 s t a g e grid f t p service

Add a DN entry to the DDI B2STAGE GridFTP service
*/
func (a *Client) AddGridmapEntry(ctx context.Context, params *AddGridmapEntryParams) (*AddGridmapEntryCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "AddGridmapEntry",
		Method:             "POST",
		PathPattern:        "/dataset/gridftp/gridmap",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &AddGridmapEntryReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*AddGridmapEntryCreated), nil

}

/*
Certificate downloads public key for w p3 a p is

download public key for WP3 APIs
*/
func (a *Client) Certificate(ctx context.Context, params *CertificateParams, writer io.Writer) (*CertificateOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "Certificate",
		Method:             "GET",
		PathPattern:        "/dataset/cert",
		ProducesMediaTypes: []string{"application/octet-stream"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CertificateReader{formats: a.formats, writer: writer},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CertificateOK), nil

}

/*
CheckCompressionEncryptionStatus checks the status of compression with encryption

Check the status of compression with encryption
*/
func (a *Client) CheckCompressionEncryptionStatus(ctx context.Context, params *CheckCompressionEncryptionStatusParams) (*CheckCompressionEncryptionStatusOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CheckCompressionEncryptionStatus",
		Method:             "GET",
		PathPattern:        "/dataset/encryption/compress_encrypt/{request_id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CheckCompressionEncryptionStatusReader{formats: a.formats},
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CheckCompressionEncryptionStatusOK), nil

}

/*
CheckCompressionStatus checks the status of a compression

Check the status of a compression
*/
func (a *Client) CheckCompressionStatus(ctx context.Context, params *CheckCompressionStatusParams) (*CheckCompressionStatusOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CheckCompressionStatus",
		Method:             "GET",
		PathPattern:        "/dataset/encryption/compress/{request_id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CheckCompressionStatusReader{formats: a.formats},
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CheckCompressionStatusOK), nil

}

/*
CheckDecompressionStatus checks the status of a decompression

Check the status of a decompression
*/
func (a *Client) CheckDecompressionStatus(ctx context.Context, params *CheckDecompressionStatusParams) (*CheckDecompressionStatusOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CheckDecompressionStatus",
		Method:             "GET",
		PathPattern:        "/dataset/encryption/decompress/{request_id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CheckDecompressionStatusReader{formats: a.formats},
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CheckDecompressionStatusOK), nil

}

/*
CheckDecryptionDecompressionStatus checks the status of decryption with decompression

Check the status of decryption with decompression
*/
func (a *Client) CheckDecryptionDecompressionStatus(ctx context.Context, params *CheckDecryptionDecompressionStatusParams) (*CheckDecryptionDecompressionStatusOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CheckDecryptionDecompressionStatus",
		Method:             "GET",
		PathPattern:        "/dataset/encryption/decrypt_decompress/{request_id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CheckDecryptionDecompressionStatusReader{formats: a.formats},
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CheckDecryptionDecompressionStatusOK), nil

}

/*
CheckDecryptionStatus checks the status of a decryption

Check the status of a decryption
*/
func (a *Client) CheckDecryptionStatus(ctx context.Context, params *CheckDecryptionStatusParams) (*CheckDecryptionStatusOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CheckDecryptionStatus",
		Method:             "GET",
		PathPattern:        "/dataset/encryption/decrypt/{request_id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CheckDecryptionStatusReader{formats: a.formats},
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CheckDecryptionStatusOK), nil

}

/*
CheckEncryptionStatus checks the status of a encryption

Check the status of a encryption
*/
func (a *Client) CheckEncryptionStatus(ctx context.Context, params *CheckEncryptionStatusParams) (*CheckEncryptionStatusOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CheckEncryptionStatus",
		Method:             "GET",
		PathPattern:        "/dataset/encryption/encrypt/{request_id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CheckEncryptionStatusReader{formats: a.formats},
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CheckEncryptionStatusOK), nil

}

/*
CheckPIDStatus this is called when a user requests to check the status of the p ID assignment

This is called when a user requests to check the status of his data replication
*/
func (a *Client) CheckPIDStatus(ctx context.Context, params *CheckPIDStatusParams) (*CheckPIDStatusOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CheckPIDStatus",
		Method:             "GET",
		PathPattern:        "/dataset/pid/{request_id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CheckPIDStatusReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CheckPIDStatusOK), nil

}

/*
CheckPermission checks if a user has permission to access a d d i location for writing

Check if a user has permission to access a DDI location for writing
*/
func (a *Client) CheckPermission(ctx context.Context, params *CheckPermissionParams) (*CheckPermissionOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CheckPermission",
		Method:             "POST",
		PathPattern:        "/dataset/checkpermission",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CheckPermissionReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CheckPermissionOK), nil

}

/*
CheckReplicateStatus this is called when a user requests to check the status of his data replication

This is called when a user requests to check the status of his data replication
*/
func (a *Client) CheckReplicateStatus(ctx context.Context, params *CheckReplicateStatusParams) (*CheckReplicateStatusOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CheckReplicateStatus",
		Method:             "GET",
		PathPattern:        "/dataset/replicate/{request_id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CheckReplicateStatusReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CheckReplicateStatusOK), nil

}

/*
CheckSizeStatus this is called when a user requests to check the status of datasize request

This is called when a user requests to check the status of datasize request
*/
func (a *Client) CheckSizeStatus(ctx context.Context, params *CheckSizeStatusParams) (*CheckSizeStatusOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CheckSizeStatus",
		Method:             "GET",
		PathPattern:        "/dataset/data/size/{request_id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CheckSizeStatusReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CheckSizeStatusOK), nil

}

/*
Compress compresses a dataset or subdataset by enqueuing the request for latter processing

Compress a dataset or subdataset (by enqueuing the request for latter processing)
If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
 - For public datasets: "public/proj"+hash+"/"+internalID
 - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
 - For project datasets: "project/proj"+hash+"/"+internalID

*/
func (a *Client) Compress(ctx context.Context, params *CompressParams) (*CompressCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "Compress",
		Method:             "POST",
		PathPattern:        "/dataset/encryption/compress",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CompressReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CompressCreated), nil

}

/*
CompressEncrypt compresses and encrypt a dataset or subdataset by enqueuing the request for latter processing

Compress and encrypt a dataset or subdataset (by enqueuing the request for latter processing)
If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
 - For public datasets: "public/proj"+hash+"/"+internalID
 - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
 - For project datasets: "project/proj"+hash+"/"+internalID

*/
func (a *Client) CompressEncrypt(ctx context.Context, params *CompressEncryptParams) (*CompressEncryptCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CompressEncrypt",
		Method:             "POST",
		PathPattern:        "/dataset/encryption/compress_encrypt",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CompressEncryptReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CompressEncryptCreated), nil

}

/*
CreateSSHFSExport exports a directory of the d d i for use via SSH f s

Export a directory of the DDI for use via SSHFS
*/
func (a *Client) CreateSSHFSExport(ctx context.Context, params *CreateSSHFSExportParams) (*CreateSSHFSExportCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "CreateSSHFSExport",
		Method:             "POST",
		PathPattern:        "/dataset/ssh/sshfsexport",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CreateSSHFSExportReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*CreateSSHFSExportCreated), nil

}

/*
Decompress decompresses a dataset or subdataset by enqueuing the request for latter processing

Decompress a dataset or subdataset (by enqueuing the request for latter processing)
If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
 - For public datasets: "public/proj"+hash+"/"+internalID
 - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
 - For project datasets: "project/proj"+hash+"/"+internalID

*/
func (a *Client) Decompress(ctx context.Context, params *DecompressParams) (*DecompressCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "Decompress",
		Method:             "POST",
		PathPattern:        "/dataset/encryption/decompress",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &DecompressReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*DecompressCreated), nil

}

/*
Decrypt decrypts a dataset or subdataset by enqueuing the request for latter processing

Decrypt a dataset or subdataset (by enqueuing the request for latter processing)
If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
 - For public datasets: "public/proj"+hash+"/"+internalID
 - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
 - For project datasets: "project/proj"+hash+"/"+internalID

*/
func (a *Client) Decrypt(ctx context.Context, params *DecryptParams) (*DecryptCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "Decrypt",
		Method:             "POST",
		PathPattern:        "/dataset/encryption/decrypt",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &DecryptReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*DecryptCreated), nil

}

/*
DecryptDecompress decrypts and decompress a dataset or subdataset by enqueuing the request for latter processing

Decrypt and decompress a dataset or subdataset (by enqueuing the request for latter processing)
If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
 - For public datasets: "public/proj"+hash+"/"+internalID
 - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
 - For project datasets: "project/proj"+hash+"/"+internalID

*/
func (a *Client) DecryptDecompress(ctx context.Context, params *DecryptDecompressParams) (*DecryptDecompressCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "DecryptDecompress",
		Method:             "POST",
		PathPattern:        "/dataset/encryption/decrypt_decompress",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &DecryptDecompressReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*DecryptDecompressCreated), nil

}

/*
DeleteDataset deletes dataset

Deletes a dataset by internalID (or subdataset by path)
*/
func (a *Client) DeleteDataset(ctx context.Context, params *DeleteDatasetParams) (*DeleteDatasetCreated, *DeleteDatasetNoContent, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "DeleteDataset",
		Method:             "DELETE",
		PathPattern:        "/dataset",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &DeleteDatasetReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, nil, err
	}
	switch value := result.(type) {
	case *DeleteDatasetCreated:
		return value, nil, nil
	case *DeleteDatasetNoContent:
		return nil, value, nil
	}
	return nil, nil, nil

}

/*
DeleteDatasetByMetadata searches for datasets based on metadata and delete them

Search for datasets based on metadata, and delete them
*/
func (a *Client) DeleteDatasetByMetadata(ctx context.Context, params *DeleteDatasetByMetadataParams) (*DeleteDatasetByMetadataNoContent, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "DeleteDatasetByMetadata",
		Method:             "DELETE",
		PathPattern:        "/dataset/search/metadata",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &DeleteDatasetByMetadataReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*DeleteDatasetByMetadataNoContent), nil

}

/*
DeleteSSHFSExport exports a directory of the d d i for use via SSH f s

Remove an SSHFS export of a directory of the DDI
*/
func (a *Client) DeleteSSHFSExport(ctx context.Context, params *DeleteSSHFSExportParams) (*DeleteSSHFSExportNoContent, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "DeleteSSHFSExport",
		Method:             "DELETE",
		PathPattern:        "/dataset/ssh/sshfsexport",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &DeleteSSHFSExportReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*DeleteSSHFSExportNoContent), nil

}

/*
DownloadDataset downloads dataset

Downloads a dataset. Use the header "Accept: application/octet-stream"
or "Accept: [*]/*" to enable the api to provide either zip content (normal
operation) or json (error reporting).

*/
func (a *Client) DownloadDataset(ctx context.Context, params *DownloadDatasetParams, writer io.Writer) (*DownloadDatasetOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "DownloadDataset",
		Method:             "POST",
		PathPattern:        "/dataset/download",
		ProducesMediaTypes: []string{"application/octet-stream"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &DownloadDatasetReader{formats: a.formats, writer: writer},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*DownloadDatasetOK), nil

}

/*
Encrypt encrypts a dataset or subdataset by enqueuing the request for latter processing

Encrypt a dataset or subdataset (by enqueuing the request for latter processing)
If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
 - For public datasets: "public/proj"+hash+"/"+internalID
 - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
 - For project datasets: "project/proj"+hash+"/"+internalID

*/
func (a *Client) Encrypt(ctx context.Context, params *EncryptParams) (*EncryptCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "Encrypt",
		Method:             "POST",
		PathPattern:        "/dataset/encryption/encrypt",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &EncryptReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*EncryptCreated), nil

}

/*
FilePatch useds to resume the upload

The Server SHOULD accept PATCH requests against any upload URL and apply the bytes contained in the message at the given offset specified by the Upload-Offset header. All PATCH requests MUST use Content-Type: application/offset+octet-stream, otherwise the server SHOULD return a 415 Unsupported Media Type status.
*/
func (a *Client) FilePatch(ctx context.Context, params *FilePatchParams) (*FilePatchNoContent, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "FilePatch",
		Method:             "PATCH",
		PathPattern:        "/dataset/upload/{id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/offset+octet-stream"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &FilePatchReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*FilePatchNoContent), nil

}

/*
FilesDelete addeds by the termination extension

When receiving a DELETE request for an existing upload the Server SHOULD free associated resources and MUST respond with the 204 No Content status confirming that the upload was terminated. For all future requests to this URL, the Server SHOULD respond with the 404 Not Found or 410 Gone status.
*/
func (a *Client) FilesDelete(ctx context.Context, params *FilesDeleteParams) (*FilesDeleteNoContent, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "FilesDelete",
		Method:             "DELETE",
		PathPattern:        "/dataset/upload/{id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &FilesDeleteReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*FilesDeleteNoContent), nil

}

/*
FilesHead useds to determine the offset at which the upload should be continued

Used to determine the offset at which the upload should be continued.
*/
func (a *Client) FilesHead(ctx context.Context, params *FilesHeadParams) (*FilesHeadOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "FilesHead",
		Method:             "HEAD",
		PathPattern:        "/dataset/upload/{id}",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &FilesHeadReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*FilesHeadOK), nil

}

/*
Listing lists file contents of a dataset

List file contents of a dataset.
*/
func (a *Client) Listing(ctx context.Context, params *ListingParams) (*ListingOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "Listing",
		Method:             "POST",
		PathPattern:        "/dataset/listing",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &ListingReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*ListingOK), nil

}

/*
OptionsDatasetUpload requests to gather information about the server s current configuration

An OPTIONS request MAY be used to gather information about the Server's current configuration. A successful response indicated by the 204 No Content or 200 OK status MUST contain the Tus-Version header. It MAY include the Tus-Extension and Tus-Max-Size headers.
*/
func (a *Client) OptionsDatasetUpload(ctx context.Context, params *OptionsDatasetUploadParams) (*OptionsDatasetUploadOK, *OptionsDatasetUploadNoContent, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "OptionsDatasetUpload",
		Method:             "OPTIONS",
		PathPattern:        "/dataset/upload/",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &OptionsDatasetUploadReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, nil, err
	}
	switch value := result.(type) {
	case *OptionsDatasetUploadOK:
		return value, nil, nil
	case *OptionsDatasetUploadNoContent:
		return nil, value, nil
	}
	return nil, nil, nil

}

/*
PID this is called when a user requests p ID assignment to a dataset

This is called when a user requests PID assignment to a dataset.
*/
func (a *Client) PID(ctx context.Context, params *PIDParams) (*PIDCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "PID",
		Method:             "POST",
		PathPattern:        "/dataset/pid/assign",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &PIDReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*PIDCreated), nil

}

/*
PostDatasetStagingDownload downloads from staging zone

Download from staging zone
If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
 - For public datasets: "public/proj"+hash+"/"+internalID
 - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
 - For project datasets: "project/proj"+hash+"/"+internalID

*/
func (a *Client) PostDatasetStagingDownload(ctx context.Context, params *PostDatasetStagingDownloadParams, writer io.Writer) (*PostDatasetStagingDownloadOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "PostDatasetStagingDownload",
		Method:             "POST",
		PathPattern:        "/dataset/staging/download",
		ProducesMediaTypes: []string{"application/json", "application/octet-stream"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &PostDatasetStagingDownloadReader{formats: a.formats, writer: writer},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*PostDatasetStagingDownloadOK), nil

}

/*
PostDatasetUpload ans empty p o s t request is used to create a new upload resource the upload length header indicates the size of the entire upload in bytes

Endpoint for the Creation extension
*/
func (a *Client) PostDatasetUpload(ctx context.Context, params *PostDatasetUploadParams) (*PostDatasetUploadCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "PostDatasetUpload",
		Method:             "POST",
		PathPattern:        "/dataset/upload/",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &PostDatasetUploadReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*PostDatasetUploadCreated), nil

}

/*
QueryDatasets searches for datasets based on metadata

Search for datasets based on metadata
*/
func (a *Client) QueryDatasets(ctx context.Context, params *QueryDatasetsParams) (*QueryDatasetsOK, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "QueryDatasets",
		Method:             "POST",
		PathPattern:        "/dataset/search/metadata",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &QueryDatasetsReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*QueryDatasetsOK), nil

}

/*
RemoveGridmapEntry removes a d n entry to the d d i b2 s t a g e grid f t p service

Remove a DN entry to the DDI B2STAGE GridFTP service
*/
func (a *Client) RemoveGridmapEntry(ctx context.Context, params *RemoveGridmapEntryParams) (*RemoveGridmapEntryNoContent, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "RemoveGridmapEntry",
		Method:             "DELETE",
		PathPattern:        "/dataset/gridftp/gridmap",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &RemoveGridmapEntryReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*RemoveGridmapEntryNoContent), nil

}

/*
Replicate this is called when a user requests data to be replicated between different systems the request will be added to the jobs queue

This is called when a user requests data to be replicated between different systems. The request will be added to the jobs queue.
*/
func (a *Client) Replicate(ctx context.Context, params *ReplicateParams) (*ReplicateCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "Replicate",
		Method:             "POST",
		PathPattern:        "/dataset/replicate",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &ReplicateReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*ReplicateCreated), nil

}

/*
Size this is called when a user requests size of a dataset

This is called when a user requests size of a dataset.
If you have a tuple [project, access, internalID] and the current user, the corresponding path should be calculated by calculating the md5 hash of the project, and then:
 - For public datasets: "public/proj"+hash+"/"+internalID
 - For user datasets: "user/proj"+hash+"/"+user+"/"+internalID
 - For project datasets: "project/proj"+hash+"/"+internalID

*/
func (a *Client) Size(ctx context.Context, params *SizeParams) (*SizeCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "Size",
		Method:             "POST",
		PathPattern:        "/dataset/data/size",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &SizeReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, err
	}
	return result.(*SizeCreated), nil

}

/*
CreateDataset creates a dataset

Creates a new dataset
*/
func (a *Client) CreateDataset(ctx context.Context, params *CreateDatasetParams) (*CreateDatasetOK, *CreateDatasetCreated, error) {

	result, err := a.transport.Submit(&runtime.ClientOperation{
		ID:                 "createDataset",
		Method:             "POST",
		PathPattern:        "/dataset",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"http"},
		Params:             params,
		Reader:             &CreateDatasetReader{formats: a.formats},
		AuthInfo:           a.authInfo,
		Context:            ctx,
		Client:             params.HTTPClient,
	})
	if err != nil {
		return nil, nil, err
	}
	switch value := result.(type) {
	case *CreateDatasetOK:
		return value, nil, nil
	case *CreateDatasetCreated:
		return nil, value, nil
	}
	return nil, nil, nil

}
